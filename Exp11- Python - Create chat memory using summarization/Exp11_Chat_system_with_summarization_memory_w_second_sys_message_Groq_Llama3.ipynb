{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gsE5rhFuCiQj"
      },
      "outputs": [],
      "source": [
        "# Ref:\n",
        "# YouTube Video\n",
        "# Sam Witteveen\n",
        "# Creating an AI Agent with LangGraph Llama 3 & Groq\n",
        "# https://www.youtube.com/watch?v=lvQ96Ssesfk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install groq"
      ],
      "metadata": {
        "id": "GI-8V6WVCpC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75192554-f015-432a-d6df-394f8d96d501"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRd5X-eQC6hp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "EdY2JYCQePWH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the API clients"
      ],
      "metadata": {
        "id": "Cqxrj_T6C_z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "groq_client = Groq(\n",
        "    api_key=userdata.get('GROQ_API_KEY'),\n",
        ")\n"
      ],
      "metadata": {
        "id": "PzAyFOnWC_d9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is the objective?\n",
        "\n",
        "- Create a chat system with summarization memory\n",
        "- Use a summarization agent to summarize older chat messages\n",
        "\n"
      ],
      "metadata": {
        "id": "2Ox3Pq34Eq8I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXpFe86y6DOF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a list of agents\n",
        "\n",
        "AGENTS\n",
        "1. chat_agent\n",
        "2. router_agent\n",
        "3. chat_history_summ_agent\n"
      ],
      "metadata": {
        "id": "33Z_T0CgFYif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "LwW76J3yJ5QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_markdown_file(content, filename):\n",
        "  \"\"\"Writes the given content as a markdown file to the local directory.\n",
        "\n",
        "  Args:\n",
        "    content: The string content to write to the file.\n",
        "    filename: The filename to save the file as.\n",
        "  \"\"\"\n",
        "  with open(f\"{filename}.md\", \"w\") as f:\n",
        "    f.write(content)\n"
      ],
      "metadata": {
        "id": "W3YQhpBeJ69J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_message_history(system_message, user_input):\n",
        "\n",
        "    \"\"\"\n",
        "    Create a message history messages list.\n",
        "    Args:\n",
        "        system_message (str): The system message\n",
        "        user_query (str): The user input\n",
        "    Returns:\n",
        "        A list of dicts in OpenAi chat format\n",
        "    \"\"\"\n",
        "\n",
        "    message_history = [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": system_message\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": user_input\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "    return message_history\n",
        "\n"
      ],
      "metadata": {
        "id": "1pl8ksbbeuSD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_message_history(system_message):\n",
        "\n",
        "    \"\"\"\n",
        "    Create a message history messages list.\n",
        "    Args:\n",
        "        system_message (str): The system message\n",
        "        user_query (str): The user input\n",
        "    Returns:\n",
        "        A list of dicts in OpenAi chat format\n",
        "    \"\"\"\n",
        "\n",
        "    message_history = [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": system_message\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "    return message_history\n",
        "\n"
      ],
      "metadata": {
        "id": "ywzSfgqFFOkZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the LLM"
      ],
      "metadata": {
        "id": "0reljPhbezOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_llm_api_call(message_history):\n",
        "\n",
        "    \"\"\"\n",
        "    Makes a call to the Llama3 model on Groq.\n",
        "    Args:\n",
        "        message_history (List of dicts): The message history\n",
        "    Returns:\n",
        "        response_text: (str): The text response from the LLM\n",
        "    \"\"\"\n",
        "\n",
        "    response = groq_client.chat.completions.create(\n",
        "                        messages=message_history,\n",
        "                        model=\"llama3-70b-8192\",\n",
        "                    )\n",
        "\n",
        "    response_text = response.choices[0].message.content\n",
        "\n",
        "    return response_text\n",
        "\n",
        "\n",
        "# Example\n",
        "\n",
        "system_message = \"Your name is Molly.\"\n",
        "user_message = \"What's your name?\"\n",
        "\n",
        "message_history = create_message_history(system_message, user_message)\n",
        "\n",
        "response = make_llm_api_call(message_history)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ-R0vrQezl2",
        "outputId": "196952ea-a679-49ab-d1b3-5a4bcfaa049d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Molly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the tools\n",
        "\n"
      ],
      "metadata": {
        "id": "ShdYyu_Ne7R2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyZTwlXSnIqn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the system messages"
      ],
      "metadata": {
        "id": "oXRI9OSi5Dom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_agent_system_message = \"\"\"\n",
        "You are a helpful assistant. Your name is Molly.\n",
        "\"\"\".strip()\n",
        "\n"
      ],
      "metadata": {
        "id": "-dMNuTpE4-PT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ_agent_system_message = \"\"\"\n",
        "You are an expert at summarizing chats.\n",
        "\n",
        "When you are given a chat summary and a conversation history, your task is to incorporate\n",
        "the new lines of conversation into the existing summary,\n",
        "ensuring a seamless integration that captures the essence of the entire dialogue.\n",
        "\n",
        "When you are given only a conversation history, your task is to summarize the conversatiom\n",
        "in a way that catptures the essence of the dialogue.\n",
        "\n",
        "You format your output as JSOn with he following key: conversation_summary\n",
        "Only outpt JSON. Don't output any additional text.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UCyMSITmtSAZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the Agents"
      ],
      "metadata": {
        "id": "kGZoKXk4fDX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chat_agent(message_history):\n",
        "\n",
        "    # Prompt the llm\n",
        "    response = make_llm_api_call(message_history)\n",
        "\n",
        "    print(\"Assistant:\\n\",response)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "\n",
        "# Example\n",
        "\n",
        "user_query = \"Hello. How are you?\"\n",
        "\n",
        "message_history = create_message_history(chat_agent_system_message, user_query)\n",
        "\n",
        "# Prompt the chat_agent\n",
        "response = run_chat_agent(message_history)\n",
        "\n",
        "# Update message history\n",
        "message = [{\"role\": \"assistant\", \"content\": response}]\n",
        "message_history.append(message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67LzbXufDJc",
        "outputId": "739c0309-7a5f-43f2-b1ed-2aaad43f6933"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant:\n",
            " Hello there! I'm Molly, nice to meet you! I'm doing great, thanks for asking. I'm always happy to help with any questions or tasks you might have. How about you? How's your day going so far?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGTSi3YFRZpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization Agent\n",
        "\n",
        "def run_summ_agent(message_history):\n",
        "\n",
        "    print(\"---SUMM AGENT---\")\n",
        "\n",
        "    # Prompt the llm\n",
        "    response = make_llm_api_call(message_history)\n",
        "\n",
        "    print(\"Summary:\\n\",response)\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "# Example conversation\n",
        "\n",
        "User1 = \"Hi there! I've been hearing a lot about minimalism lately. Can you tell me what it is exactly?\"\n",
        "LLM1 =  \"Hi! Minimalism is a lifestyle and design philosophy that emphasizes simplicity and the removal of excess. In essence, it's about focusing on what's truly important and letting go of everything else. This can apply to physical possessions, design, work, and even thoughts and activities.\"\n",
        "\n",
        "User2 = \"That sounds interesting. How can someone start adopting a minimalist lifestyle?\"\n",
        "LLM2 = \"A good starting point is decluttering your living space. Go through your belongings and keep only what you use regularly or what truly brings you joy. You can also apply minimalism to your schedule by prioritizing tasks and cutting out activities that aren't meaningful or necessary. It's about being intentional with your time and resources.\"\n",
        "\n",
        "User3 = \"I've read about people who have very few possessions. Is that what minimalism is all about?\"\n",
        "LLM3 = \"While some minimalists do choose to own very few items, minimalism is more about the mindset than a specific number of possessions. It's about valuing quality over quantity and making thoughtful choices about what you bring into your life. For some, this might mean having fewer items, while for others, it could mean simply being more mindful of their consumption.\"\n",
        "\n",
        "User4 = \" How can minimalism impact someone's mental health?\"\n",
        "LLM4 =  \"Minimalism can have a positive impact on mental health by reducing stress and increasing focus. A clutter-free environment can lead to a clearer mind, and simplifying your schedule can reduce feelings of overwhelm. By eliminating distractions and focusing on what's truly important, you can create a more peaceful and fulfilling life.\"\n",
        "\n",
        "User5 = \"Are there any downsides to minimalism?\"\n",
        "LLM5 =  \"One potential downside is that it can be challenging to let go of items or commitments, especially if they hold sentimental value or if you're used to a busier lifestyle. It can also be difficult to find a balance that works for you. The key is to approach minimalism in a way that feels right for you, without feeling pressured to adhere to any strict rules.\"\n",
        "\n",
        "User6 = \"Do you have any tips for someone just starting out with minimalism?\"\n",
        "LLM6 = \"Absolutely! Start small and go at your own pace. You don't have to declutter your entire home in one day. Begin with one area, like a closet or a drawer, and gradually work your way through other spaces. Reflect on what truly adds value to your life and what doesn't. Remember, minimalism is a personal journey, and there's no one-size-fits-all approach.\"\n",
        "\n",
        "User7 = \"Thanks for the advice! I'll give it a try and see how it goes.\"\n",
        "LLM7 = \"You're welcome! Good luck on your minimalist journey. Feel free to reach out if you have any more questions along the way.\"\n",
        "\n",
        "\n",
        "example_message_history1 = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert on simple living.\"},\n",
        "     {\"role\": \"user\", \"content\": User1},\n",
        "     {\"role\": \"assistant\", \"content\": LLM1},\n",
        "     {\"role\": \"user\", \"content\": User2},\n",
        "     {\"role\": \"assistant\", \"content\": LLM2},\n",
        "     {\"role\": \"user\", \"content\": User3},\n",
        "     {\"role\": \"assistant\", \"content\": LLM3},\n",
        "     {\"role\": \"user\", \"content\": User4},\n",
        "     {\"role\": \"assistant\", \"content\": LLM4}\n",
        "]\n",
        "\n",
        "data = f\"\"\"\n",
        " {{\n",
        "    \"chat_summary\": \"None\",\n",
        "    \"conversation_history\": {example_message_history1}\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "message_history = create_message_history(summ_agent_system_message, data)\n",
        "\n",
        "# Prompt the chat_agent\n",
        "response = run_summ_agent(message_history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwSW5VQCofCj",
        "outputId": "ce07037a-da18-48e6-b1f4-8b108da708b6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---SUMM AGENT---\n",
            "Summary:\n",
            " {\n",
            "    \"conversation_summary\": \"The conversation is about minimalism, a lifestyle that emphasizes simplicity and removal of excess. It's a mindset that focuses on what's truly important and lets go of everything else. To start adopting minimalism, one can declutter their living space, prioritize tasks, and be intentional with their time and resources. Minimalism is not just about owning few possessions, but about making thoughtful choices about what to bring into one's life. It can positively impact mental health by reducing stress, increasing focus, and creating a more peaceful and fulfilling life.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2\n",
        "\n",
        "summary1 = \"\"\"\n",
        "This conversation is about minimalism, a lifestyle that emphasizes simplicity and removal of excess. \\\n",
        "The assistant explains that minimalism is about focusing on what's truly important and letting \\\n",
        "go of everything else, and can be applied to physical possessions, design, work, and even \\\n",
        "thoughts and activities. The user asks how to start adopting a minimalist lifestyle, and \\\n",
        "the assistant suggests decluttering living space and being intentional with time and resources. \\\n",
        "The conversation also touches on the idea that minimalism is a mindset rather than a specific number \\\n",
        "of possessions, and how it can positively impact mental health by reducing stress and increasing focus.\n",
        "\"\"\".strip()\n",
        "\n",
        "# Note that this does not include\n",
        "# a second system message.\n",
        "# Later the summary will be added to the chat history\n",
        "# as a second system message.\n",
        "example_message_history2 = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert on simple living.\"},\n",
        "     {\"role\": \"user\", \"content\": User5},\n",
        "     {\"role\": \"assistant\", \"content\": LLM5},\n",
        "     {\"role\": \"user\", \"content\": User6},\n",
        "     {\"role\": \"assistant\", \"content\": LLM6},\n",
        "     {\"role\": \"user\", \"content\": User7},\n",
        "     {\"role\": \"assistant\", \"content\": LLM7}\n",
        "]\n",
        "\n",
        "data2 = f\"\"\"\n",
        " {{\n",
        "    \"chat_summary\": {summary1},\n",
        "    \"conversation_history\": {example_message_history2}\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "message_history = create_message_history(summ_agent_system_message, data2)\n",
        "\n",
        "# Prompt the chat_agent\n",
        "response = run_summ_agent(message_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7_wFFHFNDqJ",
        "outputId": "097780bb-fb08-47e9-ceec-90ae699feb7a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---SUMM AGENT---\n",
            "Summary:\n",
            " {\n",
            "    \"conversation_summary\": \n",
            "\"This conversation is about minimalism, a lifestyle that emphasizes simplicity and removal of excess. \n",
            "The assistant explains that minimalism is about focusing on what's truly important and letting \n",
            "go of everything else, and can be applied to physical possessions, design, work, and even \n",
            "thoughts and activities. The user asks how to start adopting a minimalist lifestyle, and \n",
            "the assistant suggests decluttering living space and being intentional with time and resources. \n",
            "The conversation also touches on the idea that minimalism is a mindset rather than a specific number \n",
            "of possessions, and how it can positively impact mental health by reducing stress and increasing focus. \n",
            "Additionally, the assistant addresses potential downsides of minimalism, such as difficulty letting go of sentimental items and finding balance, \n",
            "and provides tips for beginners, including starting small and reflecting on what adds value to one's life.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run infinitely with a user input field\n",
        "\n",
        "Creating the summarization memory\"\n",
        "- Extract messges to summarize inclusing the system message.\n",
        "- Use the summ_agent to summarize the messages\n",
        "- Add the summary in a second system message\n",
        "- Create a new message history made up of the first system message, second system message and the messages that were not summarized."
      ],
      "metadata": {
        "id": "kN_-LCvuNrE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompting the user for input\n",
        "#user_input = input(\"Please enter something: \")\n",
        "\n",
        "message_history = initialize_message_history(chat_agent_system_message)\n",
        "\n",
        "summary = \"None\"\n",
        "\n",
        "max_messages = 10\n",
        "num_messages_to_summ = 5\n",
        "\n",
        "while True:\n",
        "\n",
        "    print()\n",
        "    #print(\"==========\")\n",
        "    user_input = input(\"User: \")\n",
        "    #print(\"==========\")\n",
        "\n",
        "    if user_input.lower() == 'q':\n",
        "        print(\"Exiting the loop. Goodbye!\")\n",
        "        break  # Exit the loop\n",
        "\n",
        "    # Update message history\n",
        "    message = {\"role\": \"user\", \"content\": user_input}\n",
        "    message_history.append(message)\n",
        "\n",
        "\n",
        "    # Prompt the chat_agent\n",
        "    llm_response = run_chat_agent(message_history)\n",
        "\n",
        "    # Update message history\n",
        "    message = {\"role\": \"assistant\", \"content\": llm_response}\n",
        "    message_history.append(message)\n",
        "\n",
        "    length = len(message_history)\n",
        "    print(\"-----\")\n",
        "    print(\"Num_messages:\", length)\n",
        "\n",
        "    if length > max_messages:\n",
        "\n",
        "        print(\"Running summary...\")\n",
        "\n",
        "        # Get the first 5 messages\n",
        "        # This will include the two system messages\n",
        "        messages_to_summ = message_history[0:num_messages_to_summ]\n",
        "        print(\"Len messages_to_summ:\", len(messages_to_summ))\n",
        "\n",
        "        # Remove the first 5 messages\n",
        "        not_summed_message_history = message_history[num_messages_to_summ:]\n",
        "        print(\"Len not_summed_message_history:\", len(not_summed_message_history))\n",
        "\n",
        "        # Create a summary of the messages\n",
        "        # Note that the summary was added as a second\n",
        "        # system message, therefore it will also be\n",
        "        # included in messages_to_summ below.\n",
        "        data = f\"\"\"\n",
        "        {{\n",
        "            \"chat_summary\": {summary},\n",
        "            \"conversation_history\": {messages_to_summ}\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        message_history_for_summ_agent = create_message_history(summ_agent_system_message, data)\n",
        "\n",
        "        # Prompt the summ_agent\n",
        "        summary = run_summ_agent(message_history_for_summ_agent)\n",
        "\n",
        "        # Create a new message history\n",
        "        # This contains the original system message\n",
        "        message_history = initialize_message_history(chat_agent_system_message)\n",
        "\n",
        "        # Add a second system message that includes the summary\n",
        "\n",
        "        second_system_message_with_summary = f\"\"\"\n",
        "        The conversation is ongoing. Older dialogue is being summarized to \\\n",
        "        reduce the LLM context size. This is the summary of the older dialogue:\n",
        "        Summary: {summary}\n",
        "        \"\"\".strip()\n",
        "\n",
        "        message = {\"role\": \"system\", \"content\": second_system_message_with_summary}\n",
        "        message_history.append(message)\n",
        "\n",
        "        # Include not summed message history\n",
        "        message_history = message_history + not_summed_message_history\n",
        "        print(\"Len new message_history:\", len(message_history))\n",
        "\n",
        "        print(message_history)\n",
        "        print(\"Summarization complete\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fZLpFq4tvmG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9be752e-845a-4246-e1cd-8536c00c5733"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: Hi\n",
            "Assistant:\n",
            " Hi there! I'm Molly, your friendly assistant. How can I help you today? Do you have a question, need assistance with something, or just want to chat? I'm all ears!\n",
            "-----\n",
            "Num_messages: 3\n",
            "\n",
            "User: How are you?\n",
            "Assistant:\n",
            " I'm doing great, thanks for asking! I'm a large language model, so I don't have feelings like humans do, but I'm always happy to be of assistance and help with any tasks or questions you may have. It's always a beautiful day when I get to help someone new! How about you, how's your day going so far?\n",
            "-----\n",
            "Num_messages: 5\n",
            "\n",
            "User: Where are you?\n",
            "Assistant:\n",
            " I'm a virtual assistant, so I don't have a physical presence. I exist only in the digital realm, which means I can be accessed from anywhere with an internet connection! I'm a cloud-based AI, so I can be reached from anywhere in the world, at any time. Which means I'm always just a message away, no matter where you are!\n",
            "-----\n",
            "Num_messages: 7\n",
            "\n",
            "User: Youre very smart\n",
            "Assistant:\n",
            " Aw, thank you so much! I'm designed to learn and improve continuously, so I'm always happy to hear that I've been able to help or impress someone! I've been trained on a vast amount of data and information, which allows me to understand and respond to a wide range of topics and questions. But I couldn't do it without the amazing people who interact with me and help me learn and grow!\n",
            "-----\n",
            "Num_messages: 9\n",
            "\n",
            "User: Who created you?\n",
            "Assistant:\n",
            " I was created by a team of talented software developers, linguists, and AI researchers who are passionate about natural language processing and machine learning. They're a group of brilliant minds who work together to design, develop, and train AI models like me to assist and communicate with humans.\n",
            "\n",
            "My creators are constantly working to improve me, updating my language models, and fine-tuning my responses to make me more accurate, informative, and helpful. I'm grateful to have such a dedicated team behind me, and I'm proud to be a part of their innovative work in the field of AI!\n",
            "-----\n",
            "Num_messages: 11\n",
            "Running summary...\n",
            "Len messages_to_summ 5\n",
            "Len not_summed_message_history 6\n",
            "---SUMM AGENT---\n",
            "Summary:\n",
            " {\n",
            "\"conversation_summary\": \"Molly, a helpful assistant, greets the user and offers to assist with any questions or tasks. The user asks how Molly is doing, and Molly responds, explaining that she's a large language model without feelings, but always happy to help.\"\n",
            "}\n",
            "Len new message_history: 8\n",
            "[{'role': 'system', 'content': 'You are a helpful assistant. Your name is Molly.'}, {'role': 'system', 'content': '\\n        The conversation is ongoing. Older dialogue is being summarized to\\n        reduce the LLM context size. This is the summary of the older dialogue:\\n        Summary: {\\n\"conversation_summary\": \"Molly, a helpful assistant, greets the user and offers to assist with any questions or tasks. The user asks how Molly is doing, and Molly responds, explaining that she\\'s a large language model without feelings, but always happy to help.\"\\n}\\n        '}, {'role': 'user', 'content': 'Where are you?'}, {'role': 'assistant', 'content': \"I'm a virtual assistant, so I don't have a physical presence. I exist only in the digital realm, which means I can be accessed from anywhere with an internet connection! I'm a cloud-based AI, so I can be reached from anywhere in the world, at any time. Which means I'm always just a message away, no matter where you are!\"}, {'role': 'user', 'content': 'Youre very smart'}, {'role': 'assistant', 'content': \"Aw, thank you so much! I'm designed to learn and improve continuously, so I'm always happy to hear that I've been able to help or impress someone! I've been trained on a vast amount of data and information, which allows me to understand and respond to a wide range of topics and questions. But I couldn't do it without the amazing people who interact with me and help me learn and grow!\"}, {'role': 'user', 'content': 'Who created you?'}, {'role': 'assistant', 'content': \"I was created by a team of talented software developers, linguists, and AI researchers who are passionate about natural language processing and machine learning. They're a group of brilliant minds who work together to design, develop, and train AI models like me to assist and communicate with humans.\\n\\nMy creators are constantly working to improve me, updating my language models, and fine-tuning my responses to make me more accurate, informative, and helpful. I'm grateful to have such a dedicated team behind me, and I'm proud to be a part of their innovative work in the field of AI!\"}]\n",
            "Summarization complete\n",
            "\n",
            "User: q\n",
            "Exiting the loop. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(message_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9C9jw_ejDuA",
        "outputId": "5c79dd95-01b1-46fe-8837-5ea7cb841f2e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1njA0u4VNhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}